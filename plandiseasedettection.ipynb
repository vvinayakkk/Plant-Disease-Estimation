{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":182633,"sourceType":"datasetVersion","datasetId":78313},{"sourceId":153878,"sourceType":"modelInstanceVersion","modelInstanceId":130724,"modelId":153558}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport o","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-02T03:51:47.54226Z","iopub.execute_input":"2024-11-02T03:51:47.542631Z","iopub.status.idle":"2024-11-02T03:51:47.897711Z","shell.execute_reply.started":"2024-11-02T03:51:47.542593Z","shell.execute_reply":"2024-11-02T03:51:47.896675Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport random\nimport cv2\nfrom PIL import Image\nimport seaborn as sns\nimport time\n\n\nimport torch\nimport torch.nn as nn\nfrom torchvision import models\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.optim as optim\nfrom torchvision import transforms\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T04:00:15.731801Z","iopub.execute_input":"2024-11-02T04:00:15.732619Z","iopub.status.idle":"2024-11-02T04:00:15.923384Z","shell.execute_reply.started":"2024-11-02T04:00:15.732581Z","shell.execute_reply":"2024-11-02T04:00:15.922426Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntrain_dir = \"/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\"\nvalid_dir = \"/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid\"\nclasses = os.listdir(train_dir)\nprint(f\"Classes found: {classes}\")\nprint(f\"Number of classes: {len(classes)}\")\n\nclass_counts = {cls: len(os.listdir(os.path.join(train_dir, cls))) for cls in classes}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T03:51:53.776557Z","iopub.execute_input":"2024-11-02T03:51:53.776974Z","iopub.status.idle":"2024-11-02T03:51:58.776402Z","shell.execute_reply.started":"2024-11-02T03:51:53.77694Z","shell.execute_reply":"2024-11-02T03:51:58.775586Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nplt.barh(list(class_counts.keys()), list(class_counts.values()))\nplt.xlabel(\"Number of Images\")\nplt.ylabel(\"Classes\")\nplt.title(\"Number of Images per Class in Training Set\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T03:51:58.777803Z","iopub.execute_input":"2024-11-02T03:51:58.778103Z","iopub.status.idle":"2024-11-02T03:51:59.435839Z","shell.execute_reply.started":"2024-11-02T03:51:58.778072Z","shell.execute_reply":"2024-11-02T03:51:59.434654Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def display_random_images(data_dir, classes, num_images=5):\n    sample_classes = random.sample(classes, num_images)\n    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))  \n    for i, cls in enumerate(sample_classes):    \n        class_path = os.path.join(data_dir, cls)\n        img_name = random.choice(os.listdir(class_path))\n        img_path = os.path.join(class_path, img_name)\n\n        img = Image.open(img_path)\n        axes[i].imshow(img)\n        axes[i].set_title(cls)\n        axes[i].axis('off')\n    \n    plt.show()\n\ndisplay_random_images(train_dir, classes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T03:52:04.28667Z","iopub.execute_input":"2024-11-02T03:52:04.287443Z","iopub.status.idle":"2024-11-02T03:52:05.028569Z","shell.execute_reply.started":"2024-11-02T03:52:04.287395Z","shell.execute_reply":"2024-11-02T03:52:05.027646Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Preprocessing Step","metadata":{}},{"cell_type":"code","source":"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T04:01:06.719064Z","iopub.execute_input":"2024-11-02T04:01:06.719417Z","iopub.status.idle":"2024-11-02T04:01:06.747848Z","shell.execute_reply.started":"2024-11-02T04:01:06.719384Z","shell.execute_reply":"2024-11-02T04:01:06.746797Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef apply_filters(image):\n    # Convert PIL image to OpenCV format\n    image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n\n    # Apply Gaussian filtering\n    image = cv2.GaussianBlur(image, (5, 5), 0)\n\n    # Apply sharpening\n    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n    image = cv2.filter2D(image, -1, kernel)\n\n    # Convert back to PIL format\n    image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    return image\n\n# Update transformations with the custom filter function\ntrain_transforms = transforms.Compose([\n    transforms.Lambda(apply_filters),                   # Apply custom filters\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(30),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nvalid_transforms = transforms.Compose([\n    transforms.Lambda(apply_filters),                   # Apply custom filters\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:59:22.833945Z","iopub.execute_input":"2024-11-01T18:59:22.834604Z","iopub.status.idle":"2024-11-01T18:59:22.844446Z","shell.execute_reply.started":"2024-11-01T18:59:22.834562Z","shell.execute_reply":"2024-11-01T18:59:22.843525Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# Parameters to test\nbatch_sizes = [32, 64, 128, 256]\nnum_workers_options = [0, 2, 4, 8]\n\n# Test each combination\nresults = []\nfor batch_size in batch_sizes:\n    for num_workers in num_workers_options:\n        # Define data loader with current settings\n        loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers)\n        \n        # Measure loading time for a small number of batches (e.g., 10)\n        start_time = time.time()\n        for i, (images, labels) in enumerate(loader):\n            if i >= 10:  # Only load 10 batches to test speed\n                break\n        end_time = time.time()\n        \n        # Record the result\n        time_taken = end_time - start_time\n        results.append((batch_size, num_workers, time_taken))\n        print(f\"Batch size: {batch_size}, Num workers: {num_workers} -> Time: {time_taken:.4f} seconds\")\n\n# Find the best configuration\nbest_config = min(results, key=lambda x: x[2])\nprint(f\"\\nOptimal configuration - Batch size: {best_config[0]}, Num workers: {best_config[1]}, Time: {best_config[2]:.4f} seconds\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T19:11:39.985047Z","iopub.execute_input":"2024-11-01T19:11:39.985471Z","iopub.status.idle":"2024-11-01T19:13:47.534425Z","shell.execute_reply.started":"2024-11-01T19:11:39.985433Z","shell.execute_reply":"2024-11-01T19:13:47.533174Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# Define the training and validation datasets\ntrain_dataset = ImageFolder(root=train_dir, transform=train_transforms)\nvalid_dataset = ImageFolder(root=valid_dir, transform=valid_transforms)\n\n# Update data loaders with optimal settings\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nvalid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False, num_workers=4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T19:14:57.17491Z","iopub.execute_input":"2024-11-01T19:14:57.17579Z","iopub.status.idle":"2024-11-01T19:14:57.751777Z","shell.execute_reply.started":"2024-11-01T19:14:57.175753Z","shell.execute_reply":"2024-11-01T19:14:57.750959Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## VGG-16","metadata":{}},{"cell_type":"code","source":"\n\n# Load pre-trained VGG16 model\nmodel = models.vgg16(pretrained=True)\n\n# Modify the final layer for 38 classes\nnum_features = model.classifier[6].in_features\nmodel.classifier[6] = nn.Linear(num_features, 38)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T19:15:00.362971Z","iopub.execute_input":"2024-11-01T19:15:00.363722Z","iopub.status.idle":"2024-11-01T19:15:02.015823Z","shell.execute_reply.started":"2024-11-01T19:15:00.363683Z","shell.execute_reply":"2024-11-01T19:15:02.014969Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Early stopping parameters\npatience = 3\nbest_val_loss = float('inf')\nearly_stop_counter = 0\n\n# Lists to store metrics\ntrain_losses, val_losses = [], []\ntrain_accuracies, val_accuracies = [], []\n\n# Training loop\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model.train()  # Set model to training mode\n    train_loss, correct, total = 0, 0, 0\n    \n    # Training phase\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()                # Clear gradients\n        outputs = model(inputs)              # Forward pass\n        loss = criterion(outputs, labels)    # Compute loss\n        loss.backward()                      # Backpropagation\n        optimizer.step()                     # Update weights\n\n        # Calculate training accuracy\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n    \n    train_accuracy = 100 * correct / total\n    train_losses.append(train_loss)\n    train_accuracies.append(train_accuracy)\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n    \n    # Validation phase\n    model.eval()  # Set model to evaluation mode\n    valid_loss, correct, total = 0, 0, 0\n    with torch.no_grad():  # No gradient tracking\n        for inputs, labels in valid_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            valid_loss += loss.item()\n            \n            # Calculate validation accuracy\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n    \n    valid_accuracy = 100 * correct / total\n    val_losses.append(valid_loss)\n    val_accuracies.append(valid_accuracy)\n    print(f\"Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_accuracy:.2f}%\\n\")\n    \n    # Early stopping logic\n    if valid_loss < best_val_loss:\n        best_val_loss = valid_loss\n        early_stop_counter = 0\n        torch.save(model.state_dict(), 'best_model.pth')  # Save the best model\n    else:\n        early_stop_counter += 1\n        if early_stop_counter >= patience:\n            print(\"Early stopping triggered\")\n            break\n\n# Plot training and validation metrics\nplt.figure(figsize=(12, 5))\n\n# Plot loss\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\n# Plot accuracy\nplt.subplot(1, 2, 2)\nplt.plot(train_accuracies, label='Train Accuracy')\nplt.plot(val_accuracies, label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T19:15:03.45895Z","iopub.execute_input":"2024-11-01T19:15:03.459836Z","iopub.status.idle":"2024-11-01T20:51:50.568378Z","shell.execute_reply.started":"2024-11-01T19:15:03.459794Z","shell.execute_reply":"2024-11-01T20:51:50.567257Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the model state dictionary\ntorch.save(model.state_dict(), 'plant_disease_classification_model_vgg.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T20:54:44.866192Z","iopub.execute_input":"2024-11-01T20:54:44.866963Z","iopub.status.idle":"2024-11-01T20:54:45.864567Z","shell.execute_reply.started":"2024-11-01T20:54:44.866918Z","shell.execute_reply":"2024-11-01T20:54:45.863739Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to get predictions and labels for a model\ndef get_predictions_labels(model, data_loader):\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for inputs, labels in data_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    return all_preds, all_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T06:31:45.395386Z","iopub.execute_input":"2024-11-02T06:31:45.396132Z","iopub.status.idle":"2024-11-02T06:31:45.402696Z","shell.execute_reply.started":"2024-11-02T06:31:45.39609Z","shell.execute_reply":"2024-11-02T06:31:45.401651Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nimport torch\n\n# Load the saved models\n# VGG16\nmodel_vgg16 = models.vgg16(pretrained=False)\nmodel_vgg16.classifier[6] = nn.Linear(model_vgg16.classifier[6].in_features, 38)\nmodel_vgg16.load_state_dict(torch.load('plant_disease_classification_model_vgg.pth'))\nmodel_vgg16 = model_vgg16.to(device)\nmodel_vgg16.eval()\n# Get predictions and labels for both models\nvgg16_preds, vgg16_labels = get_predictions_labels(model_vgg16, valid_loader)\n\n# Generate and print classification reports\nprint(\"Classification Report for VGG16 Model:\\n\")\nprint(classification_report(vgg16_labels, vgg16_preds))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\n\ndef plot_confusion_matrix(true_labels, predicted_labels, model_name, class_names):\n    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n    \n    plt.figure(figsize=(16, 14))\n    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"inferno\", cbar=True, xticklabels=class_names, yticklabels=class_names)\n    plt.title(f\"Confusion Matrix for {model_name} Model\")\n    plt.xlabel(\"Predicted Labels\")\n    plt.ylabel(\"True Labels\")\n    plt.xticks(rotation=45, ha='right')\n    plt.yticks(rotation=0)\n    plt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T06:33:30.349591Z","iopub.execute_input":"2024-11-02T06:33:30.349987Z","iopub.status.idle":"2024-11-02T06:33:30.482752Z","shell.execute_reply.started":"2024-11-02T06:33:30.34995Z","shell.execute_reply":"2024-11-02T06:33:30.481945Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Class names (replace with actual class names if you have them)\nclass_names = [f\"Class {i}\" for i in range(38)]  # Replace with actual class names if available\n\n# Plot confusion matrix for VGG16\nplot_confusion_matrix(vgg16_labels, vgg16_preds, \"VGG16\", class_names)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ResNet-50","metadata":{}},{"cell_type":"code","source":"# Load the pre-trained ResNet50 model\nmodel_resnet = models.resnet50(pretrained=True)\n\n# Modify the final layer for 38 classes\nnum_features = model_resnet.fc.in_features\nmodel_resnet.fc = nn.Linear(num_features, 38)\n\n# Move the model to GPU if available\nmodel_resnet = model_resnet.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T21:00:28.686873Z","iopub.execute_input":"2024-11-01T21:00:28.687271Z","iopub.status.idle":"2024-11-01T21:00:29.793987Z","shell.execute_reply.started":"2024-11-01T21:00:28.687233Z","shell.execute_reply":"2024-11-01T21:00:29.793023Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define loss function and optimizer for ResNet50\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model_resnet.parameters(), lr=0.001)\n\n\n# Early stopping parameters\npatience = 3\nbest_val_loss = float('inf')\nearly_stop_counter = 0\n\n# Lists to store metrics\ntrain_losses, val_losses = [], []\ntrain_accuracies, val_accuracies = [], []\n\n# Training loop\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model_resnet.train()  # Set model to training mode\n    train_loss, correct, total = 0, 0, 0\n    \n    # Training phase\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()                # Clear gradients\n        outputs = model_resnet(inputs)        # Forward pass\n        loss = criterion(outputs, labels)    # Compute loss\n        loss.backward()                      # Backpropagation\n        optimizer.step()                     # Update weights\n\n        # Calculate training accuracy\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n    \n    train_accuracy = 100 * correct / total\n    train_losses.append(train_loss)\n    train_accuracies.append(train_accuracy)\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n    \n    # Validation phase\n    model_resnet.eval()  # Set model to evaluation mode\n    valid_loss, correct, total = 0, 0, 0\n    with torch.no_grad():  # No gradient tracking\n        for inputs, labels in valid_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model_resnet(inputs)\n            loss = criterion(outputs, labels)\n            valid_loss += loss.item()\n            \n            # Calculate validation accuracy\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n    \n    valid_accuracy = 100 * correct / total\n    val_losses.append(valid_loss)\n    val_accuracies.append(valid_accuracy)\n    print(f\"Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_accuracy:.2f}%\\n\")\n    \n    # Early stopping logic\n    if valid_loss < best_val_loss:\n        best_val_loss = valid_loss\n        early_stop_counter = 0\n        torch.save(model_resnet.state_dict(), 'best_resnet50_model.pth')  # Save the best model\n    else:\n        early_stop_counter += 1\n        if early_stop_counter >= patience:\n            print(\"Early stopping triggered\")\n            break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T21:03:21.50703Z","iopub.execute_input":"2024-11-01T21:03:21.50777Z","iopub.status.idle":"2024-11-01T22:05:42.063654Z","shell.execute_reply.started":"2024-11-01T21:03:21.50773Z","shell.execute_reply":"2024-11-01T22:05:42.062492Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot training and validation metrics\nplt.figure(figsize=(12, 5))\n\n# Plot loss\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\n# Plot accuracy\nplt.subplot(1, 2, 2)\nplt.plot(train_accuracies, label='Train Accuracy')\nplt.plot(val_accuracies, label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T22:05:51.593106Z","iopub.execute_input":"2024-11-01T22:05:51.59387Z","iopub.status.idle":"2024-11-01T22:05:52.086155Z","shell.execute_reply.started":"2024-11-01T22:05:51.593828Z","shell.execute_reply":"2024-11-01T22:05:52.085295Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the model state dictionary\ntorch.save(model_resnet.state_dict(), 'plant_disease_classification_model_resnet50.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T22:06:05.953096Z","iopub.execute_input":"2024-11-01T22:06:05.953506Z","iopub.status.idle":"2024-11-01T22:06:06.109049Z","shell.execute_reply.started":"2024-11-01T22:06:05.953461Z","shell.execute_reply":"2024-11-01T22:06:06.108279Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nimport torch\n\n# ResNet50\nmodel_resnet50 = models.resnet50(pretrained=False)\nmodel_resnet50.fc = nn.Linear(model_resnet50.fc.in_features, 38)\nmodel_resnet50.load_state_dict(torch.load('plant_disease_classification_model_resnet50.pth'))\nmodel_resnet50 = model_resnet50.to(device)\nmodel_resnet50.eval()\n\nresnet50_preds, resnet50_labels = get_predictions_labels(model_resnet50, valid_loader)\n\nprint(\"Classification Report for ResNet50 Model:\\n\")\nprint(classification_report(resnet50_labels, resnet50_preds))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Class names (replace with actual class names if you have them)\nclass_names = [f\"Class {i}\" for i in range(38)]  # Replace with actual class names if available\n# Plot confusion matrix for ResNet50\nplot_confusion_matrix(resnet50_labels, resnet50_preds, \"ResNet50\", class_names)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Inception-V3","metadata":{}},{"cell_type":"code","source":"# Define preprocessing for InceptionV3\ninception_transforms = transforms.Compose([\n    transforms.Resize((299, 299)),                  # Resize to 299x299\n    transforms.RandomHorizontalFlip(),              # Apply other augmentations as needed\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Make sure to apply these transformations in your DataLoader for InceptionV3\ntrain_dataset = ImageFolder(root=train_dir, transform=inception_transforms)\nvalid_dataset = ImageFolder(root=valid_dir, transform=inception_transforms)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\nvalid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False, num_workers=4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T03:55:01.499637Z","iopub.execute_input":"2024-11-02T03:55:01.500516Z","iopub.status.idle":"2024-11-02T03:55:56.419117Z","shell.execute_reply.started":"2024-11-02T03:55:01.500476Z","shell.execute_reply":"2024-11-02T03:55:56.418324Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load InceptionV3 model\nmodel_inception = models.inception_v3(pretrained=True)\nmodel_inception.aux_logits = False  # Disable auxiliary logits\n\n# Modify the final layer\nnum_features = model_inception.fc.in_features\nmodel_inception.fc = nn.Linear(num_features, 38)\n\n# Move model to GPU if available\nmodel_inception = model_inception.to(device)\n\n# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model_inception.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T04:01:18.655809Z","iopub.execute_input":"2024-11-02T04:01:18.656187Z","iopub.status.idle":"2024-11-02T04:01:19.256484Z","shell.execute_reply.started":"2024-11-02T04:01:18.656151Z","shell.execute_reply":"2024-11-02T04:01:19.255502Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Early stopping parameters\npatience = 3\nbest_val_loss = float('inf')\nearly_stop_counter = 0\n\n# Lists to store metrics\ntrain_losses, val_losses = [], []\ntrain_accuracies, val_accuracies = [], []\n\n# Training loop\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model_inception.train()  # Set model to training mode\n    train_loss, correct, total = 0, 0, 0\n    \n    # Training phase\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()                # Clear gradients\n        outputs = model_inception(inputs)        # Forward pass\n        loss = criterion(outputs, labels)    # Compute loss\n        loss.backward()                      # Backpropagation\n        optimizer.step()                     # Update weights\n\n        # Calculate training accuracy\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n    \n    train_accuracy = 100 * correct / total\n    train_losses.append(train_loss)\n    train_accuracies.append(train_accuracy)\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n    \n    # Validation phase\n    model_inception.eval()  # Set model to evaluation mode\n    valid_loss, correct, total = 0, 0, 0\n    with torch.no_grad():  # No gradient tracking\n        for inputs, labels in valid_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model_inception(inputs)\n            loss = criterion(outputs, labels)\n            valid_loss += loss.item()\n            \n            # Calculate validation accuracy\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n    \n    valid_accuracy = 100 * correct / total\n    val_losses.append(valid_loss)\n    val_accuracies.append(valid_accuracy)\n    print(f\"Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_accuracy:.2f}%\\n\")\n    \n    # Early stopping logic\n    if valid_loss < best_val_loss:\n        best_val_loss = valid_loss\n        early_stop_counter = 0\n        torch.save(model_inception.state_dict(), 'best_inceptionV3_model.pth')  # Save the best model\n    else:\n        early_stop_counter += 1\n        if early_stop_counter >= patience:\n            print(\"Early stopping triggered\")\n            break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T04:01:28.432263Z","iopub.execute_input":"2024-11-02T04:01:28.432642Z","iopub.status.idle":"2024-11-02T05:59:26.524682Z","shell.execute_reply.started":"2024-11-02T04:01:28.432607Z","shell.execute_reply":"2024-11-02T05:59:26.52353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot training and validation metrics\nplt.figure(figsize=(12, 5))\n\n# Plot loss\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\n# Plot accuracy\nplt.subplot(1, 2, 2)\nplt.plot(train_accuracies, label='Train Accuracy')\nplt.plot(val_accuracies, label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T06:28:06.106197Z","iopub.execute_input":"2024-11-02T06:28:06.106645Z","iopub.status.idle":"2024-11-02T06:28:06.675468Z","shell.execute_reply.started":"2024-11-02T06:28:06.106603Z","shell.execute_reply":"2024-11-02T06:28:06.674539Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models\n\n# Load the Inception v3 model with pre-trained weights\nmodel_inception = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1)\n\n# Modify the final fully connected layer to match the number of classes in your dataset\nnum_classes = 38  # Replace with the actual number of classes\nmodel_inception.fc = nn.Linear(model_inception.fc.in_features, num_classes)\n\n# Load your trained model's state dictionary\nmodel_inception.load_state_dict(torch.load('best_inceptionV3_model.pth'))\n\n# Move the model to the appropriate device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel_inception = model_inception.to(device)\nmodel_inception.eval()  # Set the model to evaluation mode\n\n# Get predictions and labels for InceptionV3\ninception_preds, inception_labels = get_predictions_labels(model_inception, valid_loader)\n\n# Print classification report\nprint(\"Classification Report for InceptionV3 Model:\\n\")\nprint(classification_report(inception_labels, inception_preds))\n\n# Class names (replace with actual class names if you have them)\nclass_names = [f\"Class {i}\" for i in range(38)]  # Replace with actual class names if available\n\n# Plot confusion matrix for InceptionV3\nplot_confusion_matrix(inception_labels, inception_preds, \"InceptionV3\", class_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T06:42:50.479559Z","iopub.execute_input":"2024-11-02T06:42:50.480451Z","iopub.status.idle":"2024-11-02T06:43:46.759495Z","shell.execute_reply.started":"2024-11-02T06:42:50.480406Z","shell.execute_reply":"2024-11-02T06:43:46.758536Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation on Test Dataset","metadata":{}},{"cell_type":"code","source":"class_names = train_dataset.classes  # This will give you the class names in the order used during training\nprint(class_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T07:09:13.102581Z","iopub.execute_input":"2024-11-02T07:09:13.103286Z","iopub.status.idle":"2024-11-02T07:09:13.108199Z","shell.execute_reply.started":"2024-11-02T07:09:13.103243Z","shell.execute_reply":"2024-11-02T07:09:13.107263Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nfrom PIL import Image\nfrom sklearn.metrics import classification_report\nfrom torchvision import transforms, models\nimport torch.nn as nn\n\n# Define the correct class names in the order used during training\nclass_names = [\n    'Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy',\n    'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy',\n    'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_',\n    'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy', 'Grape___Black_rot',\n    'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy',\n    'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy',\n    'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight',\n    'Potato___Late_blight', 'Potato___healthy', 'Raspberry___healthy', 'Soybean___healthy',\n    'Squash___Powdery_mildew', 'Strawberry___Leaf_scorch', 'Strawberry___healthy',\n    'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight',\n    'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite',\n    'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus',\n    'Tomato___healthy'\n]\n\n# Define the mapping from simple class names to full class names in class_names\nsimple_to_full_class_mapping = {\n    'TomatoEarlyBlight': 'Tomato___Early_blight',\n    'TomatoYellowCurlVirus': 'Tomato___Tomato_Yellow_Leaf_Curl_Virus',\n    'PotatoHealthy': 'Potato___healthy',\n    'PotatoEarlyBlight': 'Potato___Early_blight',\n    'CornCommonRust': 'Corn_(maize)___Common_rust_',\n    'AppleScab': 'Apple___Apple_scab',\n    'TomatoHealthy': 'Tomato___healthy',\n    'AppleCedarRust': 'Apple___Cedar_apple_rust'\n}\n\n# Define the test directory path\ntest_dir = '/kaggle/input/new-plant-diseases-dataset/test/test'\n\n# Define the same preprocessing transformations used during training\ntest_transforms = transforms.Compose([\n    transforms.Resize((299, 299)),                  # Resize to 299x299 for InceptionV3\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Standard normalization for ImageNet\n])\n\n# Load the pre-trained model with the correct output layer\nmodel_inception = models.inception_v3(pretrained=False)\nmodel_inception.fc = nn.Linear(model_inception.fc.in_features, len(class_names))  # Set the output layer size\nmodel_inception.load_state_dict(torch.load('best_inceptionV3_model.pth'))\nmodel_inception = model_inception.to(device)\nmodel_inception.eval()  # Set the model to evaluation mode\n\n# Lists to store true and predicted labels\ntrue_labels = []\npredicted_labels = []\n\n# Loop through each image in the test directory\nfor image_file in os.listdir(test_dir):\n    # Extract the base class name (e.g., 'TomatoEarlyBlight' from 'TomatoEarlyBlight6.JPG')\n    base_class_name = ''.join([i for i in image_file if not i.isdigit()]).replace(\".JPG\", \"\")\n    \n    # Map the simplified name to the full name in `class_names`\n    true_class_name = simple_to_full_class_mapping.get(base_class_name, None)\n    \n    # Find the index in `class_names` if mapping is successful\n    if true_class_name:\n        true_label = class_names.index(true_class_name)\n    else:\n        print(f\"Warning: {base_class_name} not found in class names.\")\n        continue  # Skip if class not found in mapping\n    \n    # Load and preprocess the image\n    image_path = os.path.join(test_dir, image_file)\n    image = Image.open(image_path).convert(\"RGB\")  # Ensure the image is in RGB format\n    image = test_transforms(image).unsqueeze(0).to(device)\n    \n    # Get model prediction\n    with torch.no_grad():\n        output = model_inception(image)\n        _, predicted_label = torch.max(output, 1)\n    \n    # Append to results\n    true_labels.append(true_label)\n    predicted_labels.append(predicted_label.item())\n    \n    # Print individual predictions (optional)\n    print(f\"Image: {image_file} | True Label: {true_label} ({true_class_name}) | Predicted Label: {predicted_label.item()} ({class_names[predicted_label.item()]})\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T07:11:26.866905Z","iopub.execute_input":"2024-11-02T07:11:26.867776Z","iopub.status.idle":"2024-11-02T07:11:28.55394Z","shell.execute_reply.started":"2024-11-02T07:11:26.867712Z","shell.execute_reply":"2024-11-02T07:11:28.553059Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Find unique labels in true_labels and filter class_names accordingly\nunique_labels = sorted(set(true_labels))  # Get sorted list of unique labels in the test set\nfiltered_class_names = [class_names[i] for i in unique_labels]  # Filter class names to match unique labels\n\n# Generate and print the classification report\nprint(\"\\nClassification Report for Test Set:\\n\")\nprint(classification_report(true_labels, predicted_labels, labels=unique_labels, target_names=filtered_class_names))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T07:12:05.657032Z","iopub.execute_input":"2024-11-02T07:12:05.657411Z","iopub.status.idle":"2024-11-02T07:12:05.673724Z","shell.execute_reply.started":"2024-11-02T07:12:05.657374Z","shell.execute_reply":"2024-11-02T07:12:05.672858Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Custom CNN architecture","metadata":{}},{"cell_type":"code","source":"class CustomCNN(nn.Module):\n    def __init__(self, num_classes):\n        super(CustomCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.fc1 = nn.Linear(128 * 37 * 37, 512)  # Adjust based on input size\n        self.fc2 = nn.Linear(512, num_classes)\n        self.dropout = nn.Dropout(0.5)\n        \n    def forward(self, x):\n        x = self.pool(torch.relu(self.conv1(x)))\n        x = self.pool(torch.relu(self.conv2(x)))\n        x = self.pool(torch.relu(self.conv3(x)))\n        x = x.view(-1, 128 * 37 * 37)  # Flatten\n        x = torch.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\n# Set up the custom model\nnum_classes = len(class_names)  # Adjust this based on the number of classes\nmodel_custom = CustomCNN(num_classes).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T07:22:53.794946Z","iopub.execute_input":"2024-11-02T07:22:53.795357Z","iopub.status.idle":"2024-11-02T07:22:54.633625Z","shell.execute_reply.started":"2024-11-02T07:22:53.795321Z","shell.execute_reply":"2024-11-02T07:22:54.632759Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hyperparameters\nlearning_rate = 0.001\nnum_epochs = 10\n\n# Optimizer and Loss Function\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model_custom.parameters(), lr=learning_rate)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T07:22:57.263127Z","iopub.execute_input":"2024-11-02T07:22:57.263848Z","iopub.status.idle":"2024-11-02T07:22:57.27297Z","shell.execute_reply.started":"2024-11-02T07:22:57.263799Z","shell.execute_reply":"2024-11-02T07:22:57.272067Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    model_custom.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        # Zero the parameter gradients\n        optimizer.zero_grad()\n        \n        # Forward pass\n        outputs = model_custom(inputs)\n        loss = criterion(outputs, labels)\n        \n        # Backward and optimize\n        loss.backward()\n        optimizer.step()\n        \n        # Statistics\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n    \n    # Print stats\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T07:23:03.165627Z","iopub.execute_input":"2024-11-02T07:23:03.166012Z","iopub.status.idle":"2024-11-02T08:03:20.988642Z","shell.execute_reply.started":"2024-11-02T07:23:03.165976Z","shell.execute_reply":"2024-11-02T08:03:20.987498Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluation on test set","metadata":{}},{"cell_type":"code","source":"# Evaluate on test set\nmodel_custom.eval()\ntrue_labels = []\npredicted_labels = []\n\nfor image_file in os.listdir(test_dir):\n    # Extract the base class name (e.g., 'TomatoEarlyBlight' from 'TomatoEarlyBlight6.JPG')\n    base_class_name = ''.join([i for i in image_file if not i.isdigit()]).replace(\".JPG\", \"\")\n    \n    # Map the simplified name to the full name in `class_names`\n    true_class_name = simple_to_full_class_mapping.get(base_class_name, None)\n    \n    # Find the index in `class_names` if mapping is successful\n    if true_class_name:\n        true_label = class_names.index(true_class_name)\n    else:\n        print(f\"Warning: {base_class_name} not found in class names.\")\n        continue  # Skip if class not found in mapping\n    \n    # Load and preprocess the image\n    image_path = os.path.join(test_dir, image_file)\n    image = Image.open(image_path).convert(\"RGB\")  # Ensure the image is in RGB format\n    image = test_transforms(image).unsqueeze(0).to(device)\n    \n    # Get model prediction\n    with torch.no_grad():\n        output = model_custom(image)\n        _, predicted_label = torch.max(output, 1)\n    \n    # Append to results\n    true_labels.append(true_label)\n    predicted_labels.append(predicted_label.item())\n    \n    # Print individual predictions (optional)\n    print(f\"Image: {image_file} | True Label: {true_label} ({true_class_name}) | Predicted Label: {predicted_label.item()} ({class_names[predicted_label.item()]})\")\n\n# Generate and print the classification report\nprint(\"Classification Report for Custom CNN Model on Test Set:\\n\")\nprint(classification_report(true_labels, predicted_labels, target_names=class_names))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-02T08:08:42.705088Z","iopub.execute_input":"2024-11-02T08:08:42.705515Z","iopub.status.idle":"2024-11-02T08:08:43.109749Z","shell.execute_reply.started":"2024-11-02T08:08:42.705472Z","shell.execute_reply":"2024-11-02T08:08:43.108002Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}